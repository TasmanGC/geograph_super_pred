{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\22566465\\Miniconda3\\envs\\ginn_gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# these modules are requried to import my code\n",
    "import  sys\n",
    "import  os\n",
    "from    pathlib import Path\n",
    "\n",
    "# this adds my code to the system path so it can be imported as if it were a python module\n",
    "cwd         = os.getcwd()\n",
    "geograph_interpolator_root  = Path(cwd).__str__()\n",
    "sys.path.append(geograph_interpolator_root)\n",
    "\n",
    "# import our package\n",
    "from geograph_super_pred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "basement_file = r'Data\\survey_data.csv'\n",
    "\n",
    "df = pd.read_csv(basement_file)\n",
    "df.z = df.z - df.z.max()\n",
    "df.z = df.z *10\n",
    "\n",
    "d_frame = df\n",
    "\n",
    "buffer = 10\n",
    "x       = d_frame.x\n",
    "y       = d_frame.y\n",
    "\n",
    "spline = vd.Spline(damping=0.0008)\n",
    "spline.fit((d_frame['x'],d_frame['y']), d_frame['z'])\n",
    "\n",
    "grid_coords     = vd.grid_coordinates(region=(d_frame['x'].min()-buffer, d_frame['x'].max()+buffer,d_frame['y'].min()-buffer, d_frame['y'].max()+buffer), spacing=50)\n",
    "gridded_scalars = spline.predict(grid_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_node_list = []\n",
    "\n",
    "for s in stations:\n",
    "    core_node_list.extend(s.conv2core())\n",
    "\n",
    "visualise_3D(core_node_list,'rdata')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_stations = generate_synth_stations(df,100,vert_res=20, feat_type='A')\n",
    "b_stations = generate_synth_stations(df,100,vert_res=50, feat_type='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_stations(griddf, num_stations, vert_res=30, feat_type='A'):\n",
    "\n",
    "    # for finding basement value\n",
    "    buffer = 10\n",
    "    x       = griddf.x\n",
    "    y       = griddf.y\n",
    "\n",
    "    spline = vd.Spline(damping=0.0008)\n",
    "    spline.fit((griddf['x'],griddf['y']), griddf['z'])\n",
    "\n",
    "    grid_coords     = vd.grid_coordinates(region=(griddf['x'].min()-buffer, griddf['x'].max()+buffer,griddf['y'].min()-buffer, griddf['y'].max()+buffer), spacing=50)\n",
    "    gridded_scalars = spline.predict(grid_coords)\n",
    "\n",
    "    x_array = [random.randint(griddf.x.min(),griddf.x.max()) for v in range(num_stations)]\n",
    "    y_array = [random.randint(griddf.y.min(),griddf.y.max()) for v in range(num_stations)]\n",
    "\n",
    "    station_list = []\n",
    "\n",
    "    station_z = np.linspace(0,griddf.z.min(),vert_res)\n",
    "\n",
    "    for i in range(num_stations):\n",
    "\n",
    "        # TODO you would sample the basement location from the grid based on randomly generated xy\n",
    "        basement_depth = spline.predict((float(x_array[i]),float(y_array[i]),0))\n",
    "\n",
    "        points_above = [x for x in station_z if x>basement_depth]\n",
    "        points_below = [x for x in station_z if x<=basement_depth]\n",
    "\n",
    "        # feature_type A\n",
    "        if feat_type=='A':\n",
    "            feats_above = [np.sin(x) for x in np.linspace(0,3,len(points_above))]\n",
    "            feats_below = [(np.sin(x)*-1)/2 for x in np.linspace(0,3,len(points_below))]\n",
    "\n",
    "        # feature_type B\n",
    "        if feat_type=='B':\n",
    "            feats_above = list(np.random.choice(np.linspace(-0.02, 0.02,100), len(points_above), replace=False))\n",
    "            feats_below = list(np.random.choice(np.linspace(-1, 1, 100), len(points_below), replace=False))\n",
    "        \n",
    "        loc = [x_array[i],y_array[i],basement_depth]\n",
    "        params = {'depth':station_z,'rdata':feats_above+feats_below,'label':[0]*len(points_above)+[1]*len(points_below)}\n",
    "\n",
    "        station_list.append(Station(i,loc,feat_type,params))\n",
    "\n",
    "    station_values = feats_above + feats_below\n",
    "\n",
    "    return(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "## generate the data and plot it for an ideal normal curve\n",
    "\n",
    "  \n",
    "## x-axis for the plot\n",
    "x_data = np.linspace(0,1,0.1)\n",
    "  \n",
    "## y-axis as the gaussian\n",
    "y_data = stats.norm.pdf(x_data, 0.5, 1)\n",
    "  \n",
    "## plot data\n",
    "plt.plot(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stations(feature_type, grid_df, number_of_stations=100, vertical_resolution=30, ):\n",
    "\n",
    "\n",
    "def populate_station():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the repo demo data\n",
    "node_file_name      = geograph_interpolator_root+'\\Data\\graph_features.csv'\n",
    "edge_file_name_sim  = geograph_interpolator_root+'\\Data\\graph_edges_similar.csv'\n",
    "edge_file_name_lat  = geograph_interpolator_root+'\\Data\\graph_edges_lattice.csv'\n",
    "\n",
    "core_node_list  = load_graph_nodes(node_file_name)\n",
    "lattice_edges   = load_graph_edges(edge_file_name_lat)\n",
    "similar_edges   = load_graph_edges(edge_file_name_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the different node parameters a list can be seen here: core_node_list[0].params.keys()\n",
    "# role - either training or testing\n",
    "# labl - label\n",
    "# cond - pretend conductivity\n",
    "visualise_3D(core_node_list,'cond',similar_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare global variables for later visualisation\n",
    "global graph\n",
    "global gcn_logits\n",
    "global wgcnlogits\n",
    "global gat_logits\n",
    "\n",
    "feats = ['data','zloc_n'] # feats can be a list of keys to extract from graph.ndata or number for random embedding\n",
    "insize = len(feats) if isinstance(feats,list) else feats\n",
    "\n",
    "# construct our graph objects\n",
    "graph = create_dgl_graph(core_node_list,lattice_edges)\n",
    "graph0 = create_dgl_graph(core_node_list,lattice_edges)\n",
    "graph1 = create_dgl_graph(core_node_list,lattice_edges)\n",
    "graph2 = create_dgl_graph(core_node_list,lattice_edges)\n",
    "\n",
    "# generate our GNN Models\n",
    "model_GCN = GCN(insize,5,2)\n",
    "modelwGCN = wGCN(insize,5,2)\n",
    "model_GAT = GAT(insize,5,2,5)\n",
    "\n",
    "# run interpolation using the different models\n",
    "gcn_loss, gcn_logits = gnn_interpolate(model_GCN, graph0, node_feats=feats, epochs=300)\n",
    "wgcnloss, wgcnlogits = gnn_interpolate(modelwGCN, graph1, node_feats=feats, epochs=300)\n",
    "gat_loss, gat_logits = gnn_interpolate(model_GAT, graph2, node_feats=feats, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training loss\n",
    "plt.title('Loss Value')\n",
    "plt.plot(gat_loss,label='GAT')\n",
    "plt.plot(gcn_loss,label='GCN')\n",
    "plt.plot(wgcnloss,label='wGCN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a prediction and opens a pyvista slider to move around results\n",
    "plotter = pv.Plotter(shape=(1, 3),notebook=False,window_size=(1920,1000))\n",
    "\n",
    "def create_mesh(value):\n",
    "    res = int(value)\n",
    "\n",
    "    x = graph.ndata['xloc'].flatten().detach().numpy()\n",
    "    y = graph.ndata['yloc'].flatten().detach().numpy()\n",
    "    z = graph.ndata['zloc'].flatten().detach().numpy()\n",
    "    p0 = torch.argmax(gcn_logits[res],dim=1)\n",
    "    p1 = torch.argmax(wgcnlogits[res],dim=1)\n",
    "    p2 = torch.argmax(gat_logits[res],dim=1)\n",
    "\n",
    "    # wow a pyvista object\n",
    "    vert = list(zip(x,y,z))\n",
    "\n",
    "    gcn_cloud = pv.PolyData(vert)\n",
    "    gcn_cloud['pred'] = p0    \n",
    "\n",
    "    wgcncloud = pv.PolyData(vert)\n",
    "    wgcncloud['pred'] = p1  \n",
    "\n",
    "    gat_cloud = pv.PolyData(vert)\n",
    "    gat_cloud['pred'] = p2   \n",
    "\n",
    "    # GCN\n",
    "    plotter.subplot(0, 0)\n",
    "    plotter.add_text(\"GCN\", font_size=30)\n",
    "    plotter.add_mesh(gcn_cloud,name='gcn_pointcloud')\n",
    "    \n",
    "    # wGCN\n",
    "    plotter.subplot(0, 1)\n",
    "    plotter.add_text(\"wGCN\", font_size=30)\n",
    "    plotter.add_mesh(wgcncloud,name='wgcnpointcloud')\n",
    "\n",
    "    # GAT\n",
    "    plotter.subplot(0, 2)\n",
    "    plotter.add_text(\"GAT\", font_size=30)\n",
    "    plotter.add_mesh(gat_cloud, name='gat_pointcloud')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "plotter.add_slider_widget(create_mesh, [0, 299], title='Epoch')\n",
    "plotter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d304f62fa0dfbca0cb4d5e34705838fbdc162e2c04a7547f25dfe68ea559084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
